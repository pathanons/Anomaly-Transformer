{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b075b04",
   "metadata": {},
   "source": [
    "### Progress Update : Vanilla Anomaly Transformer Focusing on Association Discrepancy in Attention Part and Other Factors\n",
    "We are focusing on the principle behide association discrepancy which includes Self-Attention (Series Asssociations) and Prior Association. In the first part, self-attention, we plotting out the self-attention to see how diffenrence between normal and abnormal points is, and how they are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98c3637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_files_to_arrays(directory):\n",
    "    \"\"\"\n",
    "    Loads all files in the specified directory into a list of numpy arrays.\n",
    "    Assumes each file contains data readable by np.load or np.loadtxt.\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                # Try loading as a numpy binary file first\n",
    "                arr = np.load(filepath)\n",
    "            except Exception:\n",
    "                # If that fails, try loading as a text file\n",
    "                arr = np.loadtxt(filepath)\n",
    "            arrays.append(arr)\n",
    "    return arrays\n",
    "\n",
    "def load_files_to_dict(directory):\n",
    "    \"\"\"\n",
    "    Loads all files in the specified directory into a dict of numpy arrays.\n",
    "    Keys are filenames.\n",
    "    \"\"\"\n",
    "    arrays = {}\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                arr = np.load(filepath)\n",
    "            except Exception:\n",
    "                arr = np.loadtxt(filepath)\n",
    "            arrays[filename] = arr\n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "761cd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allinputs = load_files_to_dict(\"./checkpoints/PSM/100/values/inputs\")\n",
    "# alllabels = load_files_to_dict(\"./checkpoints/PSM/100/values/labels\")\n",
    "# allattentions = load_files_to_dict(\"./checkpoints/PSM/100/values/attentions\")\n",
    "# allcrits = load_files_to_dict(\"./checkpoints/PSM/100/values/crits\")\n",
    "# main_path = \"C:\\\\Users\\\\Acer\\\\Documents\\\\cmu\\\\research\\\\Anomaly-Transformer\\\\checkpoints\\\\PSM\\\\110\\\\values\"\n",
    "main_path = \"../checkpoints/experiments/my_exp/SAW/120/values\"\n",
    "allinputs = load_files_to_dict(os.path.join(main_path, \"inputs\"))\n",
    "alllabels = load_files_to_dict(os.path.join(main_path, \"labels\"))\n",
    "allattentions = load_files_to_dict(os.path.join(main_path, \"attentions\"))\n",
    "allcrits = load_files_to_dict(os.path.join(main_path, \"crits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d28857f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# attention layer 0\n",
    "layer = 0\n",
    "idx_batch = 0\n",
    "file_name_template = f\"batch_{idx_batch:06d}.npy\"\n",
    "attention_key = f\"layer{layer}_batch_{idx_batch:06d}.npy\"\n",
    "# get data\n",
    "attention_matrix = allattentions[attention_key]\n",
    "crits_data = allcrits[file_name_template]\n",
    "input_data = allinputs[file_name_template]\n",
    "if alllabels:\n",
    "    label_data = alllabels[file_name_template]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e094f",
   "metadata": {},
   "source": [
    "### Series Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297cdc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_heatmap(attention_matrix, layer, batch_idx, labels=None):\n",
    "    # create save plots path\n",
    "    save_path = os.path.join(main_path, \"plots\", f\"layer{layer}\",f\"batch_{batch_idx:06d}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    # plot attention matrix\n",
    "    # attns shape: (batch_size, n_heads, win_size, win_size)\n",
    "    sample_idx = 0  # which sample in the batch to visualize (0..batch_size-1)\n",
    "    for sample_idx in range(attention_matrix.shape[0]):\n",
    "        B, H, S1, S2 = attention_matrix.shape\n",
    "        if labels is not None:\n",
    "            label = labels[sample_idx]\n",
    "            marked_indices = np.where(label == 1)[0]\n",
    "        # Create a single-row figure with H columns (one subplot per head)\n",
    "        fig, axes = plt.subplots(1, H, figsize=(8 * H, 8))\n",
    "        # If there's only one head, axes may not be an array\n",
    "        if H == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for h in range(H):\n",
    "            ax = axes[h]\n",
    "            attn = attention_matrix[sample_idx, h]\n",
    "            im = ax.imshow(attn, aspect='auto', cmap='viridis')\n",
    "            for idx in marked_indices:\n",
    "                ax.axhline(y=idx, color='red', linestyle='-', linewidth=1, alpha=0.7)\n",
    "                ax.axvline(x=idx, color='red', linestyle='-', linewidth=1, alpha=0.7)\n",
    "            ax.set_title(f'Head {h}')\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Add a single colorbar for the row of heads\n",
    "        # fig.colorbar(im, ax=axes, fraction=0.02, pad=0.02)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()\n",
    "        # plt.close() \n",
    "        filename = os.path.join(save_path, f\"sample{sample_idx:06d}.png\")    \n",
    "        fig.savefig(filename)\n",
    "        plt.close() \n",
    "\n",
    "def plot_crits(crits_data, input_data, batch_idx, labels=None):\n",
    "    # create save plots path\n",
    "    save_path = os.path.join(main_path, \"plots\", f\"crits\",f\"batch_{batch_idx:06d}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    # plot crits\n",
    "    sample_idx = 0  # which sample in the batch to visualize (0..batch_size-1)\n",
    "    for sample_idx in range(crits_data.shape[0]):\n",
    "        crits = crits_data[sample_idx]\n",
    "        inputs = input_data[sample_idx]\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(12, 6))\n",
    "        ax[0].plot(inputs, label='Input')\n",
    "        ax[1].plot(crits, label='Crits')\n",
    "        if labels is not None:\n",
    "            label = labels[sample_idx]\n",
    "            marked_indices = np.where(label == 1)[0]\n",
    "            for idx in marked_indices:\n",
    "                ax[0].axvline(x=idx, color='red', linestyle='-', linewidth=1, alpha=0.7)\n",
    "                ax[1].axvline(x=idx, color='red', linestyle='-', linewidth=1, alpha=0.7)\n",
    "        # fig.suptitle(f'Crits for Sample {sample_idx} in Batch {batch_idx}')\n",
    "        ax[0].set_xlabel('Time Step')\n",
    "        ax[0].set_ylabel('Input Value')\n",
    "        ax[1].set_xlabel('Time Step')\n",
    "        ax[1].set_ylabel('Crit Value')\n",
    "        # ax[1].set_ylim(0, 4)\n",
    "        # fig.legend()\n",
    "        filename = os.path.join(save_path, f\"sample{sample_idx:06d}_crits.png\")    \n",
    "        plt.savefig(filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191dca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x103442f90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "plot_crits(crits_data,input_data, idx_batch, labels=label_data)\n",
    "plot_attention_heatmap(attention_matrix, layer, idx_batch, labels=label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f81e1ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14564\n",
       "1      436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv('../../../Downloads/test_label.csv')\n",
    "data = pd.read_csv('../dataset/SAW/test_label.csv')\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0721ad6",
   "metadata": {},
   "source": [
    "### Prior Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b5a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62f6fb98",
   "metadata": {},
   "source": [
    "### Association Discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f07d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
